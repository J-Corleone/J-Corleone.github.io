{"meta":{"title":"Corleone","subtitle":"Charon_","description":"","author":"Corleone","url":"http://J-Corleone.github.io","root":"/"},"pages":[{"title":"404","date":"2022-05-24T20:36:26.000Z","updated":"2022-05-25T03:36:55.994Z","comments":true,"path":"404/index.html","permalink":"http://j-corleone.github.io/404/index.html","excerpt":"","text":""},{"title":"contact","date":"2022-05-24T20:32:11.000Z","updated":"2022-05-25T06:47:21.557Z","comments":true,"path":"contact/index.html","permalink":"http://j-corleone.github.io/contact/index.html","excerpt":"","text":"æœ¬åŠŸèƒ½æš‚æœªå¼€é€šä½ å¯ä»¥è‡ªè¨€è‡ªè¯­ğŸ¤ª"},{"title":"about","date":"2022-05-24T20:29:56.000Z","updated":"2022-05-25T07:19:24.322Z","comments":true,"path":"about/index.html","permalink":"http://j-corleone.github.io/about/index.html","excerpt":"","text":"è¿™é‡Œæœ‰ä¸œè¥¿å—"},{"title":"categories","date":"2022-05-24T20:26:33.000Z","updated":"2022-05-24T20:31:50.794Z","comments":true,"path":"categories/index.html","permalink":"http://j-corleone.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-05-24T20:28:28.000Z","updated":"2022-05-24T20:31:18.183Z","comments":true,"path":"tags/index.html","permalink":"http://j-corleone.github.io/tags/index.html","excerpt":"","text":""},{"title":"friends","date":"2022-05-24T20:33:19.000Z","updated":"2022-05-24T20:33:44.509Z","comments":true,"path":"friends/index.html","permalink":"http://j-corleone.github.io/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"ã€ŠSpark HA & Yarné…ç½®ã€‹","slug":"Spark3","date":"2022-05-31T05:41:17.000Z","updated":"2022-05-31T05:43:38.486Z","comments":true,"path":"2022/05/31/spark3/","link":"","permalink":"http://j-corleone.github.io/2022/05/31/spark3/","excerpt":"","text":"Spark-Standalone-HAæ¨¡å¼Spark Standaloneé›†ç¾¤æ˜¯Master-Slavesæ¶æ„çš„é›†ç¾¤æ¨¡å¼,å’Œå¤§éƒ¨åˆ†çš„Master-Slavesç»“æ„é›†ç¾¤ä¸€æ ·,å­˜åœ¨ç€Master å•ç‚¹æ•…éšœ(SPOF)çš„é—®é¢˜ã€‚ç®€å•ç†è§£ä¸ºï¼Œspark-Standalone æ¨¡å¼ä¸‹ä¸º master èŠ‚ç‚¹æ§åˆ¶å…¶ä»–èŠ‚ç‚¹ï¼Œå½“ master èŠ‚ç‚¹å‡ºç°æ•…éšœæ—¶ï¼Œé›†ç¾¤å°±ä¸å¯ç”¨äº†ã€‚ spark-Standalone-HA æ¨¡å¼ä¸‹master èŠ‚ç‚¹ä¸å›ºå®šï¼Œå½“ä¸€ä¸ªå®•æœºæ—¶ï¼Œç«‹å³æ¢å¦ä¸€å°ä¸º master ä¿éšœä¸å‡ºç°æ•…éšœã€‚æ­¤å¤„å› ä¸ºå…ˆå‰é…ç½®æ—¶çš„ zookeeper ç‰ˆæœ¬å’Œ spark ç‰ˆæœ¬ä¸å¤ªå…¼å®¹ï¼Œå¯¼è‡´æ­¤æ¨¡å¼æœ‰æ•…éšœï¼Œéœ€è¦é‡æ–°ä¸‹è½½é…ç½®æ–°çš„ç‰ˆæœ¬çš„ zookeeperé…ç½®ä¹‹å‰éœ€è¦åˆ é™¤ä¸‰å°ä¸»æœºçš„ æ—§ç‰ˆ zookeeper ä»¥åŠ å¯¹åº”çš„è½¯è¿æ¥åœ¨ master èŠ‚ç‚¹ä¸Šé‡æ–°è¿›è¡Œå‰é¢é…ç½®çš„ zookeeper æ“ä½œ 1.ä¸Šä¼ apache-zookeeper-3.7.0-bin.tar.gz åˆ°/export/server/ç›®å½•ä¸‹ å¹¶è§£å‹æ–‡ä»¶ 2.åœ¨ /export/server ç›®å½•ä¸‹åˆ›å»ºè½¯è¿æ¥ 3.è¿›å…¥ /export/server/zookeeper/conf/ å°† zoo_sample.cfg æ–‡ä»¶å¤åˆ¶ä¸ºæ–°æ–‡ä»¶ zoo.cfg 4.æ¥ä¸Šæ­¥ç»™ zoo.cfg æ·»åŠ å†…å®¹ 5.è¿›å…¥ /export/server/zookeeper/zkdatas ç›®å½•åœ¨æ­¤ç›®å½•ä¸‹åˆ›å»º myid æ–‡ä»¶ï¼Œå°† 1 å†™å…¥è¿› å»6.å°† master èŠ‚ç‚¹ä¸­ /export/server/zookeeper-3.7.0 è·¯å¾„ä¸‹å†…å®¹æ¨é€ç»™slave1 å’Œ slave2 7.æ¨é€æˆåŠŸåï¼Œåˆ†åˆ«åœ¨ slave1 å’Œ slave2 ä¸Šåˆ›å»ºè½¯è¿æ¥ 8.æ¥ä¸Šæ­¥æ¨é€å®Œæˆåå°† slave1 å’Œ slave2 çš„ /export/server/zookeeper/zkdatas/æ–‡ä»¶å¤¹ ä¸‹çš„ myid ä¸­çš„å†…å®¹åˆ†åˆ«æ”¹ä¸º 2 å’Œ 3 é…ç½®ç¯å¢ƒå˜é‡ï¼š å› å…ˆå‰é…ç½® zookeeper æ—¶å€™åˆ›å»ºè¿‡è½¯è¿æ¥ä¸”ä»¥ â€™zookeeperâ€˜ ä¸ºè·¯å¾„ï¼Œæ‰€ä»¥ä¸ç”¨é…ç½®ç¯å¢ƒå˜é‡ï¼Œæ­¤ å¤„ä¹Ÿæ˜¯åˆ›å»ºè½¯è¿æ¥çš„æ–¹ä¾¿ä¹‹å¤„ è¿›å…¥ /export/server/spark/conf æ–‡ä»¶å¤¹ ä¿®æ”¹ spark-env.sh æ–‡ä»¶å†…å®¹ cd /export/server/spark/confvim spark-env.sh ä¸º 83 è¡Œå†…å®¹åŠ ä¸Šæ³¨é‡Šï¼Œæ­¤éƒ¨åˆ†åŸä¸ºæŒ‡å®š æŸå°ä¸»æœº åš master ï¼ŒåŠ ä¸Šæ³¨é‡Šåå³ä¸º ä»»ä½•ä¸»æœºéƒ½å¯ä»¥åš master ç»“æœæ˜¾ç¤ºï¼šâ€¦â€¦82 # å‘ŠçŸ¥Sparkçš„masterè¿è¡Œåœ¨å“ªä¸ªæœºå™¨ä¸Š 83 # export SPARK_MASTER_HOST=masterâ€¦â€¦â€¦ æ–‡æœ«æ·»åŠ å†…å®¹ SPARK_DAEMON_JAVA_OPTS=â€-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 - Dspark.deploy.zookeeper.dir=/spark-haâ€#spark.deploy.recoveryModeæŒ‡å®šHAæ¨¡å¼ åŸºäºZookeeperå®ç°#æŒ‡å®šZookeeperçš„è¿æ¥åœ°å€#æŒ‡å®šåœ¨Zookeeperä¸­æ³¨å†Œä¸´æ—¶èŠ‚ç‚¹çš„è·¯å¾„ åˆ†å‘ spark-env.sh åˆ° salve1 å’Œ slave2 ä¸Š scp spark-env.sh slave1:/export/server/spark/conf/ scp spark-env.sh slave2:/export/server/spark/conf/ å¯åŠ¨ä¹‹å‰ç¡®ä¿ Zookeeper å’Œ HDFS å‡å·²ç»å¯åŠ¨å¯åŠ¨é›†ç¾¤: #åœ¨ master ä¸Š å¯åŠ¨ä¸€ä¸ªmaster å’Œå…¨éƒ¨worker /export/server/spark/sbin/start-all.sh # æ³¨æ„, ä¸‹é¢å‘½ä»¤åœ¨ slave1 ä¸Šæ‰§è¡Œ å¯åŠ¨ slave1 ä¸Šçš„ master åšå¤‡ç”¨ master /export/server/spark/sbin/start-master.shç»“æœæ˜¾ç¤ºï¼š(base) [root@master ~]# jps37328 DataNode41589 Master35798 QuorumPeerMain38521 ResourceManager46281 Jps38907 NodeManager41821 Worker36958 NameNode (base)[root@slave1 sbin]# jps36631 DataNode48135 Master35385 QuorumPeerMain37961 NodeManager40970 Worker48282 Jps37276 SecondaryNameNode è®¿é—® WebUI ç•Œé¢ http://master:8081/ http://slave1:8082/ æ­¤æ—¶ kill æ‰ master ä¸Šçš„ master å‡è®¾ master ä¸»æœºå®•æœºæ‰ #masterä¸»æœº master çš„è¿›ç¨‹å· kill -9 41589 ç»“æœæ˜¾ç¤ºï¼š (base) [root@master ~]# jps 37328 DataNode 90336 Jps 35798 QuorumPeerMain 38521 ResourceManager 38907 NodeManager 41821 Worker 36958 NameNode è®¿é—® slave1 çš„ WebUI http://slave1:8082/ è¿›è¡Œä¸»å¤‡åˆ‡æ¢çš„æµ‹è¯•æäº¤ä¸€ä¸ª spark ä»»åŠ¡åˆ°å½“å‰ æ´»è·ƒçš„ masterä¸Š : /export/server/spark/bin/spark-submit â€“master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000 å¤åˆ¶æ ‡ç­¾ kill æ‰ master çš„ è¿›ç¨‹å·å†æ¬¡è®¿é—® master çš„ WebUI http://master:8081/ç½‘é¡µè®¿é—®ä¸äº†ï¼ å†æ¬¡è®¿é—® slave1 çš„ WebUI http://slave1:8082/ å¯ä»¥çœ‹åˆ°å½“å‰æ´»è·ƒçš„ master æç¤ºä¿¡æ¯ (base) [root@master ~]# /export/server/spark/bin/spark-submit â€“master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000 22/03/29 16:11:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platformâ€¦ using builtin-java classes where applicable 22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnectâ€¦ 22/03/29 16:12:16 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnectionâ€¦ 22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnectâ€¦ Pi is roughly 3.140960 (base) [root@master ~]# Spark On YARNæ¨¡å¼ åœ¨å·²æœ‰YARNé›†ç¾¤çš„å‰æä¸‹åœ¨å•ç‹¬å‡†å¤‡Spark StandAloneé›†ç¾¤,å¯¹èµ„æºçš„åˆ©ç”¨å°±ä¸é«˜.Spark On YARN, æ—  éœ€éƒ¨ç½²Sparké›†ç¾¤, åªè¦æ‰¾ä¸€å°æœåŠ¡å™¨, å……å½“Sparkçš„å®¢æˆ·ç«¯ä¿è¯ HADOOP_CONF_å’Œ DIR_YARN_CONF_DIR å·²ç»é…ç½®åœ¨ spark-env.sh å’Œç¯å¢ƒå˜é‡ä¸­ ï¼ˆæ³¨: å‰é¢é…ç½®spark-Standlone æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰ spark-env.sh æ–‡ä»¶éƒ¨åˆ†æ˜¾ç¤ºï¼š â€¦. 77 ## HADOOPè½¯ä»¶é…ç½®æ–‡ä»¶ç›®å½•ï¼Œè¯»å–HDFSä¸Šæ–‡ä»¶å’Œè¿è¡ŒYARNé›†ç¾¤ 78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop 79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop â€¦. é“¾æ¥åˆ° YARN ä¸­ï¼ˆæ³¨: äº¤äº’å¼ç¯å¢ƒ pyspark å’Œ spark-shell æ— æ³•è¿è¡Œ clusteræ¨¡å¼ï¼‰bin/pyspark â€“master yarn â€“deploy-mode client|cluster # â€“deploy-mode é€‰é¡¹æ˜¯æŒ‡å®šéƒ¨ç½²æ¨¡å¼, é»˜è®¤æ˜¯ å®¢æˆ·ç«¯æ¨¡å¼ # clientå°±æ˜¯å®¢æˆ·ç«¯æ¨¡å¼ # clusterå°±æ˜¯é›†ç¾¤æ¨¡å¼ # â€“deploy-mode ä»…å¯ä»¥ç”¨åœ¨YARNæ¨¡å¼ä¸‹bin/spark-shell â€“master yarn â€“deploy-mode client|clusterbin/spark-submit â€“master yarn â€“deploy-mode client|cluster /xxx/xxx/xxx.py å‚æ•° spark-submit å’Œ spark-shell å’Œ pysparkçš„ç›¸å…³å‚æ•° bin/pyspark: pysparkè§£é‡Šå™¨sparkç¯å¢ƒ - bin/spark-shell: scalaè§£é‡Šå™¨sparkç¯å¢ƒ - bin/spark-submit: æäº¤jaråŒ…æˆ–Pythonæ–‡ä»¶æ‰§è¡Œçš„å·¥å…· - bin/spark-sql: sparksqlå®¢æˆ·ç«¯å·¥å…· è¿™4ä¸ªå®¢æˆ·ç«¯å·¥å…·çš„å‚æ•°åŸºæœ¬é€šç”¨.ä»¥spark-submit ä¸ºä¾‹: bin/spark-submit â€“master spark://master:7077 xxx.py` Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]Usage: spark-submit â€“kill [submission ID] â€“master [spark://â€¦]Usage: spark-submit â€“status [submission ID] â€“master [spark://â€¦]Usage: spark-submit run-example [options] example-class [example args] Options: â€“master MASTER_URL spark://host:port, mesos://host:port, yarn, k8s://https://host:port, or local (Default: local[*]). â€“deploy-mode DEPLOY_MODE éƒ¨ç½²æ¨¡å¼ client æˆ–è€… cluster é»˜è®¤æ˜¯client â€“class CLASS_NAME è¿è¡Œjavaæˆ–è€…scala class(for Java / Scala apps). â€“name NAME ç¨‹åºçš„åå­— â€“jars JARS Comma-separated list of jars to include on the driver and executor classpaths. â€“packages Comma-separated list of maven coordinates of jars to include on the driver and executor classpaths. Will search the local maven repo, then maven central and any additional remote repositories given by â€“repositories. The format for the coordinates should be groupId:artifactId:version.â€“exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided inâ€“ packages to avoid dependency conflicts. â€“repositories Comma-separated list of additional remote repositories to search for the maven coordinates given withâ€“ packages.â€“py-files PY_FILES æŒ‡å®šPythonç¨‹åºä¾èµ–çš„å…¶å®ƒpythonæ–‡ä»¶â€“files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName).â€“archives ARCHIVES Comma-separated list of archives to be extracted into the working directory of each executor.â€“conf,-c PROP=VALUE æ‰‹åŠ¨æŒ‡å®šé…ç½®â€“properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf/spark- defaults.conf. â€“driver-memory MEM Driverçš„å¯ç”¨å†…å­˜(Default: 1024M). â€“driver-java-options Driverçš„ä¸€äº›Javaé€‰é¡¹ â€“driver-library-path Extra library path entries to pass to the driver. â€“driver-class-path Extra class path entries to pass to the driver. Note that jars added with â€“jars are automatically included in the classpath.â€“executor-memory MEM Executorçš„å†…å­˜ (Default: 1G).â€“proxy-user NAME User to impersonate when submitting the application. This argument does not work withâ€“principal /â€“keytab.â€“help,-h æ˜¾ç¤ºå¸®åŠ©æ–‡ä»¶â€“verbose,-v Print additional debug output. â€“version, æ‰“å°ç‰ˆæœ¬ Cluster deploy mode only(é›†ç¾¤æ¨¡å¼ä¸“å±):â€“driver-cores NUM Driverå¯ç”¨çš„çš„CPUæ ¸æ•°(Default: 1). Spark standalone or Mesos with cluster deploy mode only:â€“supervise å¦‚æœç»™å®š, å¯ä»¥å°è¯•é‡å¯Driver Spark standalone, Mesos or K8s with cluster deploy mode only:â€“kill SUBMISSION_ID æŒ‡å®šç¨‹åºID kill â€“status SUBMISSION_ID æŒ‡å®šç¨‹åºID æŸ¥çœ‹è¿è¡ŒçŠ¶æ€ Spark standalone, Mesos and Kubernetes only:â€“total-executor-cores NUM æ•´ä¸ªä»»åŠ¡å¯ä»¥ç»™Executorå¤šå°‘ä¸ªCPUæ ¸å¿ƒç”¨ Spark standalone, YARN and Kubernetes only:â€“executor-cores NUM å•ä¸ªExecutorèƒ½ä½¿ç”¨å¤šå°‘CPUæ ¸å¿ƒ Spark on YARN and Kubernetes only(YARNæ¨¡å¼ä¸‹):â€“num-executors NUM Executoråº”è¯¥å¼€å¯å‡ ä¸ªâ€“principal PRINCIPAL Principal to be used to login to KDC.â€“keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. Spark on YARN only:â€“queue QUEUE_NAME æŒ‡å®šè¿è¡Œçš„YARNé˜Ÿåˆ—(Default: â€œdefaultâ€) å¯åŠ¨ YARN çš„å†å²æœåŠ¡å™¨ cd /export/server/hadoop-3.3.0/sbin ./mr-jobhistory-daemon.sh start historyserver è®¿é—®WebUIç•Œé¢ http://master:19888/ client æ¨¡å¼æµ‹è¯• SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit â€“master yarn â€“deploy-mode client â€“ driver-memory 512m â€“executor-memory 512m â€“num-executors 1 â€“total- executor-cores 2 ${SPARK_HOME}/examples/src/main/python/pi.py cluster æ¨¡å¼æµ‹è¯• SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit â€“master yarn â€“deploy-mode cluster â€“driver- memory 512m â€“executor-memory 512m â€“num-executors 1 â€“total-executor-cores 2 â€“conf â€œspark.pyspark.driver.python=/root/anaconda3/bin/python3â€ â€“conf â€œspark.pyspark.python=/root/anaconda3/bin/python3â€ ${SPARK_HOME}/examples/src/main/python/pi.py 3**","categories":[],"tags":[]},{"title":"ã€ŠSpark local& stand-aloneé…ç½®ã€‹","slug":"Spark2","date":"2022-05-31T05:36:26.000Z","updated":"2022-05-31T05:41:06.167Z","comments":true,"path":"2022/05/31/spark2/","link":"","permalink":"http://j-corleone.github.io/2022/05/31/spark2/","excerpt":"","text":"Spark Standaloneé›†ç¾¤æ˜¯Master-Slavesæ¶æ„çš„é›†ç¾¤æ¨¡å¼,å’Œå¤§éƒ¨åˆ†çš„Master-Slavesç»“æ„é›†ç¾¤ä¸€æ ·,å­˜åœ¨ç€Master å•ç‚¹æ•…éšœ(SPOF)çš„é—®é¢˜ã€‚ç®€å•ç†è§£ä¸ºï¼Œspark-Standalone æ¨¡å¼ä¸‹ä¸º master èŠ‚ç‚¹æ§åˆ¶å…¶ä»–èŠ‚ç‚¹ï¼Œå½“ master èŠ‚ç‚¹å‡ºç°æ•…éšœæ—¶ï¼Œé›†ç¾¤å°±ä¸å¯ç”¨äº†ã€‚ spark-Standalone-HA æ¨¡å¼ä¸‹master èŠ‚ç‚¹ä¸å›ºå®šï¼Œå½“ä¸€ä¸ªå®•æœºæ—¶ï¼Œç«‹å³æ¢å¦ä¸€å°ä¸º master ä¿éšœä¸å‡ºç°æ•…éšœã€‚æ­¤å¤„å› ä¸ºå…ˆå‰é…ç½®æ—¶çš„ zookeeper ç‰ˆæœ¬å’Œ spark ç‰ˆæœ¬ä¸å¤ªå…¼å®¹ï¼Œå¯¼è‡´æ­¤æ¨¡å¼æœ‰æ•…éšœï¼Œéœ€è¦é‡æ–°ä¸‹è½½é…ç½®æ–°çš„ç‰ˆæœ¬çš„ zookeeperé…ç½®ä¹‹å‰éœ€è¦åˆ é™¤ä¸‰å°ä¸»æœºçš„ æ—§ç‰ˆ zookeeper ä»¥åŠ å¯¹åº”çš„è½¯è¿æ¥åœ¨ master èŠ‚ç‚¹ä¸Šé‡æ–°è¿›è¡Œå‰é¢é…ç½®çš„ zookeeper æ“ä½œ 1.ä¸Šä¼ apache-zookeeper-3.7.0-bin.tar.gz åˆ°/export/server/ç›®å½•ä¸‹ å¹¶è§£å‹æ–‡ä»¶ 2.åœ¨ /export/server ç›®å½•ä¸‹åˆ›å»ºè½¯è¿æ¥ 3.è¿›å…¥ /export/server/zookeeper/conf/ å°† zoo_sample.cfg æ–‡ä»¶å¤åˆ¶ä¸ºæ–°æ–‡ä»¶ zoo.cfg 4.æ¥ä¸Šæ­¥ç»™ zoo.cfg æ·»åŠ å†…å®¹ 5.è¿›å…¥ /export/server/zookeeper/zkdatas ç›®å½•åœ¨æ­¤ç›®å½•ä¸‹åˆ›å»º myid æ–‡ä»¶ï¼Œå°† 1 å†™å…¥è¿› å»6.å°† master èŠ‚ç‚¹ä¸­ /export/server/zookeeper-3.7.0 è·¯å¾„ä¸‹å†…å®¹æ¨é€ç»™slave1 å’Œ slave2 7.æ¨é€æˆåŠŸåï¼Œåˆ†åˆ«åœ¨ slave1 å’Œ slave2 ä¸Šåˆ›å»ºè½¯è¿æ¥ 8.æ¥ä¸Šæ­¥æ¨é€å®Œæˆåå°† slave1 å’Œ slave2 çš„ /export/server/zookeeper/zkdatas/æ–‡ä»¶å¤¹ ä¸‹çš„ myid ä¸­çš„å†…å®¹åˆ†åˆ«æ”¹ä¸º 2 å’Œ 3 é…ç½®ç¯å¢ƒå˜é‡ï¼š å› å…ˆå‰é…ç½® zookeeper æ—¶å€™åˆ›å»ºè¿‡è½¯è¿æ¥ä¸”ä»¥ â€™zookeeperâ€˜ ä¸ºè·¯å¾„ï¼Œæ‰€ä»¥ä¸ç”¨é…ç½®ç¯å¢ƒå˜é‡ï¼Œæ­¤ å¤„ä¹Ÿæ˜¯åˆ›å»ºè½¯è¿æ¥çš„æ–¹ä¾¿ä¹‹å¤„ è¿›å…¥ /export/server/spark/conf æ–‡ä»¶å¤¹ ä¿®æ”¹ spark-env.sh æ–‡ä»¶å†…å®¹ cd /export/server/spark/confvim spark-env.sh ä¸º 83 è¡Œå†…å®¹åŠ ä¸Šæ³¨é‡Šï¼Œæ­¤éƒ¨åˆ†åŸä¸ºæŒ‡å®š æŸå°ä¸»æœº åš master ï¼ŒåŠ ä¸Šæ³¨é‡Šåå³ä¸º ä»»ä½•ä¸»æœºéƒ½å¯ä»¥åš master ç»“æœæ˜¾ç¤ºï¼šâ€¦â€¦82 # å‘ŠçŸ¥Sparkçš„masterè¿è¡Œåœ¨å“ªä¸ªæœºå™¨ä¸Š 83 # export SPARK_MASTER_HOST=masterâ€¦â€¦â€¦ æ–‡æœ«æ·»åŠ å†…å®¹ SPARK_DAEMON_JAVA_OPTS=â€-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 - Dspark.deploy.zookeeper.dir=/spark-haâ€#spark.deploy.recoveryModeæŒ‡å®šHAæ¨¡å¼ åŸºäºZookeeperå®ç°#æŒ‡å®šZookeeperçš„è¿æ¥åœ°å€#æŒ‡å®šåœ¨Zookeeperä¸­æ³¨å†Œä¸´æ—¶èŠ‚ç‚¹çš„è·¯å¾„ åˆ†å‘ spark-env.sh åˆ° salve1 å’Œ slave2 ä¸Š scp spark-env.sh slave1:/export/server/spark/conf/ scp spark-env.sh slave2:/export/server/spark/conf/ å¯åŠ¨ä¹‹å‰ç¡®ä¿ Zookeeper å’Œ HDFS å‡å·²ç»å¯åŠ¨å¯åŠ¨é›†ç¾¤: #åœ¨ master ä¸Š å¯åŠ¨ä¸€ä¸ªmaster å’Œå…¨éƒ¨worker /export/server/spark/sbin/start-all.sh # æ³¨æ„, ä¸‹é¢å‘½ä»¤åœ¨ slave1 ä¸Šæ‰§è¡Œ å¯åŠ¨ slave1 ä¸Šçš„ master åšå¤‡ç”¨ master /export/server/spark/sbin/start-master.shç»“æœæ˜¾ç¤ºï¼š(base) [root@master ~]# jps37328 DataNode41589 Master35798 QuorumPeerMain38521 ResourceManager46281 Jps38907 NodeManager41821 Worker36958 NameNode (base)[root@slave1 sbin]# jps36631 DataNode48135 Master35385 QuorumPeerMain37961 NodeManager40970 Worker48282 Jps37276 SecondaryNameNode è®¿é—® WebUI ç•Œé¢ http://master:8081/ http://slave1:8082/ æ­¤æ—¶ kill æ‰ master ä¸Šçš„ master å‡è®¾ master ä¸»æœºå®•æœºæ‰ #masterä¸»æœº master çš„è¿›ç¨‹å· kill -9 41589 ç»“æœæ˜¾ç¤ºï¼š (base) [root@master ~]# jps 37328 DataNode 90336 Jps 35798 QuorumPeerMain 38521 ResourceManager 38907 NodeManager 41821 Worker 36958 NameNode è®¿é—® slave1 çš„ WebUI http://slave1:8082/ è¿›è¡Œä¸»å¤‡åˆ‡æ¢çš„æµ‹è¯•æäº¤ä¸€ä¸ª spark ä»»åŠ¡åˆ°å½“å‰ æ´»è·ƒçš„ masterä¸Š : /export/server/spark/bin/spark-submit â€“master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000 å¤åˆ¶æ ‡ç­¾ kill æ‰ master çš„ è¿›ç¨‹å·å†æ¬¡è®¿é—® master çš„ WebUI http://master:8081/ç½‘é¡µè®¿é—®ä¸äº†ï¼ å†æ¬¡è®¿é—® slave1 çš„ WebUI http://slave1:8082/ å¯ä»¥çœ‹åˆ°å½“å‰æ´»è·ƒçš„ master æç¤ºä¿¡æ¯ (base) [root@master ~]# /export/server/spark/bin/spark-submit â€“master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000 22/03/29 16:11:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platformâ€¦ using builtin-java classes where applicable 22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnectâ€¦ 22/03/29 16:12:16 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnectionâ€¦ 22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnectâ€¦ Pi is roughly 3.140960 (base) [root@master ~]# Spark On YARNæ¨¡å¼ åœ¨å·²æœ‰YARNé›†ç¾¤çš„å‰æä¸‹åœ¨å•ç‹¬å‡†å¤‡Spark StandAloneé›†ç¾¤,å¯¹èµ„æºçš„åˆ©ç”¨å°±ä¸é«˜.Spark On YARN, æ—  éœ€éƒ¨ç½²Sparké›†ç¾¤, åªè¦æ‰¾ä¸€å°æœåŠ¡å™¨, å……å½“Sparkçš„å®¢æˆ·ç«¯ä¿è¯ HADOOP_CONF_å’Œ DIR_YARN_CONF_DIR å·²ç»é…ç½®åœ¨ spark-env.sh å’Œç¯å¢ƒå˜é‡ä¸­ ï¼ˆæ³¨: å‰é¢é…ç½®spark-Standlone æ—¶å·²ç»é…ç½®è¿‡æ­¤é¡¹äº†ï¼‰ spark-env.sh æ–‡ä»¶éƒ¨åˆ†æ˜¾ç¤ºï¼š â€¦. 77 ## HADOOPè½¯ä»¶é…ç½®æ–‡ä»¶ç›®å½•ï¼Œè¯»å–HDFSä¸Šæ–‡ä»¶å’Œè¿è¡ŒYARNé›†ç¾¤ 78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop 79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop â€¦. é“¾æ¥åˆ° YARN ä¸­ï¼ˆæ³¨: äº¤äº’å¼ç¯å¢ƒ pyspark å’Œ spark-shell æ— æ³•è¿è¡Œ clusteræ¨¡å¼ï¼‰bin/pyspark â€“master yarn â€“deploy-mode client|cluster # â€“deploy-mode é€‰é¡¹æ˜¯æŒ‡å®šéƒ¨ç½²æ¨¡å¼, é»˜è®¤æ˜¯ å®¢æˆ·ç«¯æ¨¡å¼ # clientå°±æ˜¯å®¢æˆ·ç«¯æ¨¡å¼ # clusterå°±æ˜¯é›†ç¾¤æ¨¡å¼ # â€“deploy-mode ä»…å¯ä»¥ç”¨åœ¨YARNæ¨¡å¼ä¸‹bin/spark-shell â€“master yarn â€“deploy-mode client|clusterbin/spark-submit â€“master yarn â€“deploy-mode client|cluster /xxx/xxx/xxx.py å‚æ•° spark-submit å’Œ spark-shell å’Œ pysparkçš„ç›¸å…³å‚æ•° bin/pyspark: pysparkè§£é‡Šå™¨sparkç¯å¢ƒ - bin/spark-shell: scalaè§£é‡Šå™¨sparkç¯å¢ƒ - bin/spark-submit: æäº¤jaråŒ…æˆ–Pythonæ–‡ä»¶æ‰§è¡Œçš„å·¥å…· - bin/spark-sql: sparksqlå®¢æˆ·ç«¯å·¥å…· è¿™4ä¸ªå®¢æˆ·ç«¯å·¥å…·çš„å‚æ•°åŸºæœ¬é€šç”¨.ä»¥spark-submit ä¸ºä¾‹: bin/spark-submit â€“master spark://master:7077 xxx.py` Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]Usage: spark-submit â€“kill [submission ID] â€“master [spark://â€¦]Usage: spark-submit â€“status [submission ID] â€“master [spark://â€¦]Usage: spark-submit run-example [options] example-class [example args] Options: â€“master MASTER_URL spark://host:port, mesos://host:port, yarn, k8s://https://host:port, or local (Default: local[*]). â€“deploy-mode DEPLOY_MODE éƒ¨ç½²æ¨¡å¼ client æˆ–è€… cluster é»˜è®¤æ˜¯client â€“class CLASS_NAME è¿è¡Œjavaæˆ–è€…scala class(for Java / Scala apps). â€“name NAME ç¨‹åºçš„åå­— â€“jars JARS Comma-separated list of jars to include on the driver and executor classpaths. â€“packages Comma-separated list of maven coordinates of jars to include on the driver and executor classpaths. Will search the local maven repo, then maven central and any additional remote repositories given by â€“repositories. The format for the coordinates should be groupId:artifactId:version.â€“exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided inâ€“ packages to avoid dependency conflicts. â€“repositories Comma-separated list of additional remote repositories to search for the maven coordinates given withâ€“ packages.â€“py-files PY_FILES æŒ‡å®šPythonç¨‹åºä¾èµ–çš„å…¶å®ƒpythonæ–‡ä»¶â€“files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName).â€“archives ARCHIVES Comma-separated list of archives to be extracted into the working directory of each executor.â€“conf,-c PROP=VALUE æ‰‹åŠ¨æŒ‡å®šé…ç½®â€“properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf/spark- defaults.conf. â€“driver-memory MEM Driverçš„å¯ç”¨å†…å­˜(Default: 1024M). â€“driver-java-options Driverçš„ä¸€äº›Javaé€‰é¡¹ â€“driver-library-path Extra library path entries to pass to the driver. â€“driver-class-path Extra class path entries to pass to the driver. Note that jars added with â€“jars are automatically included in the classpath.â€“executor-memory MEM Executorçš„å†…å­˜ (Default: 1G).â€“proxy-user NAME User to impersonate when submitting the application. This argument does not work withâ€“principal /â€“keytab.â€“help,-h æ˜¾ç¤ºå¸®åŠ©æ–‡ä»¶â€“verbose,-v Print additional debug output. â€“version, æ‰“å°ç‰ˆæœ¬ Cluster deploy mode only(é›†ç¾¤æ¨¡å¼ä¸“å±):â€“driver-cores NUM Driverå¯ç”¨çš„çš„CPUæ ¸æ•°(Default: 1). Spark standalone or Mesos with cluster deploy mode only:â€“supervise å¦‚æœç»™å®š, å¯ä»¥å°è¯•é‡å¯Driver Spark standalone, Mesos or K8s with cluster deploy mode only:â€“kill SUBMISSION_ID æŒ‡å®šç¨‹åºID kill â€“status SUBMISSION_ID æŒ‡å®šç¨‹åºID æŸ¥çœ‹è¿è¡ŒçŠ¶æ€ Spark standalone, Mesos and Kubernetes only:â€“total-executor-cores NUM æ•´ä¸ªä»»åŠ¡å¯ä»¥ç»™Executorå¤šå°‘ä¸ªCPUæ ¸å¿ƒç”¨ Spark standalone, YARN and Kubernetes only:â€“executor-cores NUM å•ä¸ªExecutorèƒ½ä½¿ç”¨å¤šå°‘CPUæ ¸å¿ƒ Spark on YARN and Kubernetes only(YARNæ¨¡å¼ä¸‹):â€“num-executors NUM Executoråº”è¯¥å¼€å¯å‡ ä¸ªâ€“principal PRINCIPAL Principal to be used to login to KDC.â€“keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. Spark on YARN only:â€“queue QUEUE_NAME æŒ‡å®šè¿è¡Œçš„YARNé˜Ÿåˆ—(Default: â€œdefaultâ€) å¯åŠ¨ YARN çš„å†å²æœåŠ¡å™¨ cd /export/server/hadoop-3.3.0/sbin ./mr-jobhistory-daemon.sh start historyserver è®¿é—®WebUIç•Œé¢ http://master:19888/ client æ¨¡å¼æµ‹è¯• SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit â€“master yarn â€“deploy-mode client â€“ driver-memory 512m â€“executor-memory 512m â€“num-executors 1 â€“total- executor-cores 2 ${SPARK_HOME}/examples/src/main/python/pi.py cluster æ¨¡å¼æµ‹è¯• SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit â€“master yarn â€“deploy-mode cluster â€“driver- memory 512m â€“executor-memory 512m â€“num-executors 1 â€“total-executor-cores 2 â€“conf â€œspark.pyspark.driver.python=/root/anaconda3/bin/python3â€ â€“conf â€œspark.pyspark.python=/root/anaconda3/bin/python3â€ ${SPARK_HOME}/examples/src/main/python/pi.py 3** ã€ŠSpark local&amp; stand-aloneé…ç½®ã€‹ ** æœ¬åœ°æ¨¡å¼(å•æœº) æœ¬åœ°æ¨¡å¼å°±æ˜¯ä»¥ä¸€ä¸ªç‹¬ç«‹çš„è¿›ç¨‹,é€šè¿‡å…¶å†…éƒ¨çš„å¤šä¸ªçº¿ç¨‹æ¥æ¨¡æ‹Ÿæ•´ä¸ªSparkè¿è¡Œæ—¶ç¯å¢ƒAnaconda On Linux å®‰è£… (å•å°æœåŠ¡å™¨è„šæœ¬å®‰è£…)å®‰è£…ä¸Šä¼ å®‰è£…åŒ…: èµ„æ–™ä¸­æä¾›çš„Anaconda3-2021.05-Linux-x86_64.shæ–‡ä»¶åˆ°LinuxæœåŠ¡å™¨ä¸Šå®‰è£…ä½ç½®åœ¨ /export/server: cd /export/server#è¿è¡Œæ–‡ä»¶ sh Anaconda3-2021.05-Linux-x86_64.shè¿‡ç¨‹æ˜¾ç¤ºï¼šâ€¦#å‡ºç°å†…å®¹é€‰ yes Please answer â€˜yesâ€™ or â€˜noâ€™:â€™ &gt;&gt;&gt; yes â€¦#å‡ºç°æ·»åŠ è·¯å¾„ï¼š/export/server/anaconda3â€¦[/root/anaconda3] /export/server/anaconda3 PREFIX=/export/server/anaconda3â€¦ å®‰è£…å®Œæˆå, é€€å‡ºç»ˆç«¯ï¼Œ é‡æ–°è¿›æ¥: exitç»“æœæ˜¾ç¤ºï¼š#çœ‹åˆ°è¿™ä¸ªBaseå¼€å¤´è¡¨æ˜å®‰è£…å¥½äº†.baseæ˜¯é»˜è®¤çš„è™šæ‹Ÿç¯å¢ƒ. Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1 (base)[root@node1 ~]# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ pyspark åŸºäº python3.8 conda create -n pyspark python=3.8 åˆ‡æ¢åˆ°è™šæ‹Ÿç¯å¢ƒå†… conda activate pyspark ç»“æœæ˜¾ç¤ºï¼š (base) [root@node1 ~]# conda activate pyspark (pyspark) [root@node1 ~]# åœ¨è™šæ‹Ÿç¯å¢ƒå†…å®‰è£…åŒ… ï¼ˆæœ‰WARNINGä¸ç”¨ç®¡ï¼‰ pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simple spark å®‰è£…å°†æ–‡ä»¶ä¸Šä¼ åˆ° /export/server é‡Œé¢ ï¼Œè§£å‹ cd /export/server # è§£å‹ tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/ å»ºç«‹è½¯è¿æ¥ ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark æ·»åŠ ç¯å¢ƒå˜é‡ SPARK_HOME: è¡¨ç¤ºSparkå®‰è£…è·¯å¾„åœ¨å“ªé‡ŒPYSPARK_PYTHON: è¡¨ç¤ºSparkæƒ³è¿è¡ŒPythonç¨‹åº, é‚£ä¹ˆå»å“ªé‡Œæ‰¾pythonæ‰§è¡Œå™¨JAVA_HOME: å‘ŠçŸ¥Spark Javaåœ¨å“ªé‡ŒHADOOP_CONF_DIR: å‘ŠçŸ¥Spark Hadoopçš„é…ç½®æ–‡ä»¶åœ¨å“ªé‡ŒHADOOP_HOME: å‘ŠçŸ¥Spark Hadoopå®‰è£…åœ¨å“ªé‡Œ vim /etc/profileå†…å®¹ï¼šâ€¦..æ³¨ï¼šæ­¤éƒ¨åˆ†ä¹‹å‰é…ç½®è¿‡ï¼Œæ­¤éƒ¨åˆ†ä¸éœ€è¦åœ¨é…ç½®#JAVA_HOME export JAVA_HOME=/export/server/jdk1.8.0_241 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar #HADOOP_HOME export HADOOP_HOME=/export/server/hadoop-3.3.0 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin #ZOOKEEPER_HOME export ZOOKEEPER_HOME=/export/server/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin â€¦.. #å°†ä»¥ä¸‹éƒ¨åˆ†æ·»åŠ è¿›å» #SPARK_HOME export SPARK_HOME=/export/server/spark #HADOOP_CONF_DIR export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop #PYSPARK_PYTHON export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/pythonvim .bashrcå†…å®¹æ·»åŠ è¿›å»ï¼š #JAVA_HOMEexport JAVA_HOME=/export/server/jdk1.8.0_241#PYSPARK_PYTHONexport PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ source /etc/profilesource ~/.bashrc è¿›å…¥ /export/server/anaconda3/envs/pyspark/bin/ æ–‡ä»¶å¤¹ cd /export/server/anaconda3/envs/pyspark/bin/ å¼€å¯ ./pyspark ç»“æœæ˜¾ç¤ºï¼š (base) [root@master bin]# ./pysparkPython 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0] :: Anaconda, Inc. on linuxType â€œhelpâ€, â€œcopyrightâ€, â€œcreditsâ€ or â€œlicenseâ€ for more information.Setting default log level to â€œWARNâ€. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 2022-03-15 20:37:04,612 WARN util.NativeCodeLoader: Unable to load native- hadoop library for your platformâ€¦ using builtin-java classes where applicableWelcome to __ / / ___ ****/ /***\\ / _ / _ `/ */ â€˜*//* / .**/,*// //_\\ version 3.2.0//Using Python version 3.8.12 (default, Oct 12 2021 13:49:34) Spark context Web UI available at http://master:4040 Spark context available as â€˜scâ€™ (master = local[], app id = local- 1647347826262). SparkSession available as â€˜sparkâ€™. &gt;&gt;&gt; æŸ¥çœ‹WebUIç•Œé¢ æµè§ˆå™¨è®¿é—®ï¼šhttp://node1:4040/ é€€å‡º conda deactivate Standaloneæ¨¡å¼(é›†ç¾¤) Sparkä¸­çš„å„ä¸ªè§’è‰²ä»¥ç‹¬ç«‹è¿›ç¨‹çš„å½¢å¼å­˜åœ¨,å¹¶ç»„æˆSparké›†ç¾¤ç¯å¢ƒ Anaconda On Linux å®‰è£… (å•å°æœåŠ¡å™¨è„šæœ¬å®‰è£… æ³¨ï¼šåœ¨ slave1 å’Œ slave2 ä¸Šéƒ¨ç½²)å®‰è£…ä¸Šä¼ å®‰è£…åŒ…: èµ„æ–™ä¸­æä¾›çš„Anaconda3-2021.05-Linux-x86_64.shæ–‡ä»¶åˆ°LinuxæœåŠ¡å™¨ä¸Šå®‰è£…ä½ç½®åœ¨ /export/server: cd /export/server # è¿è¡Œæ–‡ä»¶ sh Anaconda3-2021.05-Linux-x86_64.sh è¿‡ç¨‹æ˜¾ç¤ºï¼šâ€¦#å‡ºç°å†…å®¹é€‰ yesPlease answer â€˜yesâ€™ or â€˜noâ€™:â€™yesâ€¦#å‡ºç°æ·»åŠ è·¯å¾„ï¼š/export/server/anaconda3â€¦[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3 PREFIX=/export/server/anaconda3â€¦ å®‰è£…å®Œæˆå, é€€å‡ºç»ˆç«¯ï¼Œ é‡æ–°è¿›æ¥:exitç»“æœæ˜¾ç¤ºï¼š#çœ‹åˆ°è¿™ä¸ªBaseå¼€å¤´è¡¨æ˜å®‰è£…å¥½äº†.baseæ˜¯é»˜è®¤çš„è™šæ‹Ÿç¯å¢ƒ.Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1â€¦ åœ¨ master èŠ‚ç‚¹ä¸ŠæŠŠ ./bashrc å’Œ profile åˆ†å‘ç»™ slave1 å’Œ slave2 #åˆ†å‘ .bashrc : scp /.bashrc root@slave1:/ scp /.bashrc root@slave2:/ #åˆ†å‘ profile : scp /etc/profile/ root@slave1:/etc/ scp /etc/profile/ root@slave2:/etc/â€¦ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ pyspark åŸºäº python3.8 conda create -n pyspark python=3.8 åˆ‡æ¢åˆ°è™šæ‹Ÿç¯å¢ƒå†… conda activate pyspark ç»“æœæ˜¾ç¤ºï¼š (base) [root@node1 ~]# conda activate pyspark (pyspark)åœ¨è™šæ‹Ÿç¯å¢ƒå†…å®‰è£…åŒ… ï¼ˆæœ‰WARNINGä¸ç”¨ç®¡ï¼‰pip install pyhive pyspark jieba -i https://pypi.tuna.tsinghua.edu.cn/simplespark å®‰è£…å°†æ–‡ä»¶ä¸Šä¼ åˆ° /export/server é‡Œé¢ ï¼Œè§£å‹ master èŠ‚ç‚¹èŠ‚ç‚¹è¿›å…¥ /export/server/spark/conf ä¿®æ”¹ä»¥ä¸‹é…ç½®æ–‡ä»¶ cd /export/server/spark/conf å°†æ–‡ä»¶ workers.template æ”¹åä¸º workersï¼Œå¹¶é…ç½®æ–‡ä»¶å†…å®¹ mv workers.template workers vim workers# localhoståˆ é™¤ï¼Œå†…å®¹è¿½åŠ æ–‡æœ«ï¼š node1node2node3# åŠŸèƒ½: è¿™ä¸ªæ–‡ä»¶å°±æ˜¯æŒ‡ç¤ºäº† å½“å‰SparkStandAloneç¯å¢ƒä¸‹, æœ‰å“ªäº›worker å°†æ–‡ä»¶ spark-env.sh.template æ”¹åä¸º spark-env.shï¼Œå¹¶é…ç½®ç›¸å…³å†…å®¹ mv spark-env.sh.template spark-env.sh vim spark-env.sh æ–‡æœ«è¿½åŠ å†…å®¹ï¼š##è®¾ç½®JAVAå®‰è£…ç›®å½• JAVA_HOME=/export/server/jdk##HADOOPè½¯ä»¶é…ç½®æ–‡ä»¶ç›®å½•ï¼Œè¯»å–HDFSä¸Šæ–‡ä»¶å’Œè¿è¡ŒYARNé›†ç¾¤ HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop YARN_CONF_DIR=/export/server/hadoop/etc/hadoop ## æŒ‡å®šsparkè€å¤§Masterçš„IPå’Œæäº¤ä»»åŠ¡çš„é€šä¿¡ç«¯å£ # å‘ŠçŸ¥Sparkçš„masterè¿è¡Œåœ¨å“ªä¸ªæœºå™¨ä¸Š export SPARK_MASTER_HOST=master#å‘ŠçŸ¥sparkmasterçš„é€šè®¯ç«¯å£ export SPARK_MASTER_PORT=7077# å‘ŠçŸ¥spark masterçš„ webuiç«¯å£ SPARK_MASTER_WEBUI_PORT=8080# worker cpuå¯ç”¨æ ¸æ•° SPARK_WORKER_CORES=1# workerå¯ç”¨å†…å­˜ SPARK_WORKER_MEMORY=1g# workerçš„å·¥ä½œé€šè®¯åœ°å€ SPARK_WORKER_PORT=7078# workerçš„ webuiåœ°å€ SPARK_WORKER_WEBUI_PORT=8081## è®¾ç½®å†å²æœåŠ¡å™¨ # é…ç½®çš„æ„æ€æ˜¯ å°†sparkç¨‹åºè¿è¡Œçš„å†å²æ—¥å¿— å­˜åˆ°hdfsçš„/sparklogæ–‡ä»¶å¤¹ä¸­ SPARK_HISTORY_OPTS=â€- Dspark.history.fs.logDirectory=hdfs://master:8020/sparklog/ - Dspark.history.fs.cleaner.enabled=trueâ€ å¼€å¯ hadoop çš„ hdfs å’Œ yarn é›†ç¾¤ start-dfs.sh start-yarn.sh åœ¨HDFSä¸Šåˆ›å»ºç¨‹åºè¿è¡Œå†å²è®°å½•å­˜æ”¾çš„æ–‡ä»¶å¤¹ï¼ŒåŒæ · conf æ–‡ä»¶ç›®å½•ä¸‹: hadoop fs -mkdir /sparklog hadoop fs -chmod 777 /sparklog å°† spark-defaults.conf.template æ”¹ä¸º spark-defaults.conf å¹¶åšç›¸å…³é…ç½® mv spark-defaults.conf.template spark-defaults.conf vim spark-defaults.conf æ–‡æœ«è¿½åŠ å†…å®¹ä¸ºï¼š # å¼€å¯sparkçš„æ—¥æœŸè®°å½•åŠŸèƒ½ spark.eventLog.enabled true # è®¾ç½®sparkæ—¥å¿—è®°å½•çš„è·¯å¾„ spark.eventLog.dir hdfs://master:8020/sparklog/ # è®¾ç½®sparkæ—¥å¿—æ˜¯å¦å¯åŠ¨å‹ç¼© spark.eventLog.compress true é…ç½® log4j.properties æ–‡ä»¶ å°†æ–‡ä»¶ç¬¬ 19 è¡Œçš„ log4j.rootCategory=INFO, console æ”¹ä¸ºlog4j.rootCategory=WARN, console ï¼ˆå³å°†INFO æ”¹ä¸º WARN ç›®çš„ï¼šè¾“å‡ºæ—¥å¿—, è®¾ç½®çº§åˆ«ä¸ºWARN åªè¾“å‡ºè­¦å‘Šå’Œé”™è¯¯æ—¥å¿—ï¼ŒINFO åˆ™ä¸ºè¾“å‡ºæ‰€æœ‰ä¿¡æ¯ï¼Œå¤šæ•°ä¸ºæ— ç”¨ä¿¡æ¯ï¼‰ mv log4j.properties.template log4j.properties vim log4j.properties ç»“æœæ˜¾ç¤ºï¼šâ€¦18 # Set everything to be logged to the console19 log4j.rootCategory=WARN, console â€¦. master èŠ‚ç‚¹åˆ†å‘ spark å®‰è£…æ–‡ä»¶å¤¹ åˆ° slave1 å’Œ slave2 ä¸Š master èŠ‚ç‚¹åˆ†å‘ spark å®‰è£…æ–‡ä»¶å¤¹ åˆ° slave1 å’Œ slave2 ä¸Š åœ¨slave1 å’Œ slave2 ä¸Šåšè½¯è¿æ¥ ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡ source /etc/profile è¿›å…¥ /export/server/spark/sbin æ–‡ä»¶ç›®å½•ä¸‹ å¯åŠ¨ start-history-server.sh cd /export/server/spark/sbin ./start-history-server.sh è®¿é—® WebUI ç•Œé¢ æµè§ˆå™¨è®¿é—®ï¼š http://master:18080/","categories":[],"tags":[]},{"title":"ã€ŠsparkåŸºç¡€ç¯å¢ƒé…ç½®ã€‹","slug":"Spark1","date":"2022-05-31T05:25:52.000Z","updated":"2022-05-31T05:36:01.740Z","comments":true,"path":"2022/05/31/spark1/","link":"","permalink":"http://j-corleone.github.io/2022/05/31/spark1/","excerpt":"","text":"æ‰“å¼€ä¸€ä¸ªhostsæ˜ å°„æ–‡ä»¶,ä¸ºäº†ä¿è¯åç»­ç›¸äº’å…³è”çš„è™šæ‹Ÿæœºèƒ½å¤Ÿé€šè¿‡ä¸»æœºåè¿›è¡Œè®¿é—®ï¼Œæ ¹æ®å®é™…éœ€æ±‚é…ç½®å¯¹åº”çš„IPå’Œä¸»æœºåæ˜ å°„ï¼Œåˆ†åˆ«å°†ä¸»æœºåmasterã€slave1ã€slave2 ä¸IPåœ°å€ 192.168.88.134ã€192.168.88.135 å’Œ192.168.88.136è¿›è¡Œäº†åŒ¹é…æ˜ å°„(è¿™é‡Œé€šå¸¸è¦æ ¹æ®å®é™…éœ€è¦ï¼Œå°†è¦æ­å»ºçš„é›†ç¾¤ä¸»æœºéƒ½é…ç½®ä¸»æœºåå’ŒIPæ˜ å°„)ã€‚ç¼–è¾‘ /etc/hosts æ–‡ä»¶ vim /etc/hostså†…å®¹ä¿®æ”¹ä¸ºï¼ˆæ³¨ï¼šä¸‰å°ä¸»æœºå†…å®¹ä¸€æ ·ï¼‰localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.88.135 node1192.168.88.136 node2192.168.88.137 node3 ä¸‰ã€é›†ç¾¤é…ç½®æ—¶é—´åŒæ­¥å®šä¹‰ï¼šç½‘ç»œæ—¶é—´æœåŠ¡åè®®ï¼ˆNetwork Time Protocol, NTPï¼‰ï¼Œæ˜¯ç”¨æ¥ä½¿è®¡ç®—æœºæ—¶é—´åŒæ­¥åŒ–çš„ä¸€ç§åè®®ï¼Œå®ƒå¯ä»¥ä½¿è®¡ç®—æœºå¯¹å…¶æœåŠ¡å™¨åšæ—¶é—´åŒæ­¥åŒ–ã€‚åŸå› ï¼šæ—¶é—´åŒæ­¥æœåŠ¡å™¨ï¼Œé¡¾åæ€ä¹‰å°±æ˜¯æ¥åŒæ­¥æ—¶é—´çš„ã€‚åœ¨é›†ç¾¤ä¸­åŒæ­¥æ—¶é—´æœ‰ç€ååˆ†é‡è¦çš„ä½œç”¨ï¼Œè´Ÿè½½å‡è¡¡é›†ç¾¤æˆ–é«˜å¯ç”¨é›†ç¾¤å¦‚æœæ—¶é—´ä¸ä¸€è‡´ï¼Œåœ¨æœåŠ¡å™¨ä¹‹é—´çš„æ•°æ®è¯¯å·®å°±ä¼šå¾ˆå¤§ï¼Œå¯»æ‰¾æ•°æ®ä¾¿ä¼šæˆä¸ºä¸€ä»¶æ£˜æ‰‹çš„äº‹æƒ…ã€‚è‹¥æ˜¯æ—¶é—´æ— æ³•åŒæ­¥ï¼Œé‚£ä¹ˆå°±ç®—æ˜¯å¤‡ä»½äº†æ•°æ®ï¼Œä½ ä¹Ÿå¯èƒ½æ— æ³•åœ¨æ­£ç¡®çš„æ—¶é—´å°†æ­£ç¡®çš„æ•°æ®å¤‡ä»½ã€‚é‚£æŸå¤±å¯å°±å¤§äº†ã€‚yum å®‰è£… ntp ï¼ˆæ³¨ï¼šä¸‰å°ä¸»æœºåšåŒæ ·æ“ä½œï¼‰ yum install ntp -yå¼€æœºè‡ªå¯åŠ¨ntpsystemctl enable ntpd &amp;&amp; systemctl start ntpdç»“æœæ˜¾ç¤ºï¼š [root@master ~]# systemctl enable ntpd &amp;&amp; systemctl start ntpd Created symlink from /etc/systemd/system/multi- user.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service. æˆæƒ 192.168.88.0-192.168.10.255 ç½‘æ®µä¸Šçš„æ‰€æœ‰æœºå™¨å¯ä»¥ä»è¿™å°æœºå™¨ä¸ŠæŸ¥è¯¢å’ŒåŒæ­¥æ—¶é—´ #æŸ¥çœ‹ntpé…ç½®æ–‡ä»¶ls -al /etc | grep â€˜ntpâ€™#æ˜¾ç¤ºå†…å®¹[root@node1 etc]# ls -al /etc | grep â€˜ntpâ€™drwxr-xr-x 3 root root 52 3æœˆ 10 18:25 ntp-rw-râ€“râ€“ 1 root root 2041 3æœˆ 10 20:03 ntp.conf#ç¼–è¾‘å†…å®¹æ·»åŠ  restrict 192.168.88.0 mask 255.255.255.0 ï¼ˆæ³¨ï¼šåœ¨17è¡Œå·¦å³ï¼‰ vim /etc/ntp.conf16 # Hosts on local network are less restricted.17 restrict 192.168.88.0 mask 255.255.255.0 é›†ç¾¤åœ¨å±€åŸŸç½‘ä¸­ï¼Œä¸ä½¿ç”¨å…¶ä»–äº’è”ç½‘ä¸Šçš„æ—¶é—´ #ä¿®æ”¹ /etc/ntpd.conf å†…å®¹ vim vim /etc/ntp.conf # å°†21-24è¡Œå†…å®¹æ³¨é‡Šæ‰ï¼ˆæ³¨ï¼šåŸæ¥æœªæ³¨é‡Šï¼‰ 21 #server 0.centos.pool.ntp.org iburst 22 #server 1.centos.pool.ntp.org iburst 23 #server 2.centos.pool.ntp.org iburst 24 #server 3.centos.pool.ntp.org iburst # åœ¨25è¡Œæ·»åŠ  server masterIP å³ä¸ºï¼š server 192.168.88.135 node å’Œ node3 ç›¸åŒæ“ä½œä¸‰å°ä¸»æœºåŒæ—¶æ‰§è¡Œ systemctl enable ntpd &amp;&amp; systemctl start ntpd æŸ¥çœ‹ntpç«¯å£ [root@master etc]# ss -tupln | grep â€˜123â€™ udp UNCONN 0 0 192.168.88.135:123 : users:((â€œntpdâ€,pid=54823,fd=19)) udp UNCONN 0 0 127.0.0.1:123 : users:((â€œntpdâ€,pid=54823,fd=18)) udp UNCONN 0 0 :123 *: users:((â€œntpdâ€,pid=54823,fd=16)) udp UNCONN 0 0 [fe80::2832:5f98:5bc0:e621]%ens33:123 [::]:* users:((â€œntpdâ€,pid=54823,fd=23)) udp UNCONN 0 0 [::1]:123 [::]:* users:((â€œntpdâ€,pid=54823,fd=20)) udp UNCONN 0 0 [::]:123 [::]:* users:((â€œntpdâ€,pid=54823,fd=17)) é…ç½®å®Œæˆåä¸‰å°ä¸»æœºéƒ½éœ€è¦é‡å¯ shutdown -r 0 ä¸‰å°ä¸»æœºåŒæ—¶æ‰§è¡Œï¼ˆæ³¨ï¼šæ­¤è¿‡ç¨‹éœ€è¦5åˆ†é’Ÿå·¦å³ï¼‰ ntpstat ä¸‰ã€sshå…å¯†é’¥ç™»é™†SSHå…å¯†é’¥ç™»é™†å¯ä»¥æ›´åŠ æ–¹ä¾¿çš„å®ç°ä¸åŒè®¡ç®—æœºä¹‹é—´çš„è¿æ¥å’Œåˆ‡æ¢master ç”Ÿæˆå…¬é’¥ç§é’¥ (ä¸€è·¯å›è½¦)ssh-keygen #ç»“æœæ˜¾ç¤ºï¼š[root@master .ssh]# ssh-keygen Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:QUAgFH5KBc/Erlf1JWSBbKeEepPJqMBqpWbc02/uFj8 root@master The keyâ€™s randomart image is:+â€”[RSA 2048]â€”-+| .=++oo+.o+. || . . ...o . ||. o.++ *.+ o | |.o ++ B ... | |o.=o.o .S | |.*oo.. . | |+ .. . o | | + E | | =o . | +----[SHA256]-----+ æŸ¥çœ‹éšè—çš„ .ssh æ–‡ä»¶ la -al .ssh # ç»“æœæ˜¾ç¤º [root@master ~]# ls -al .ssh/ æ€»ç”¨é‡ 16 drwx------ 2 root root 80 3æœˆ 10 21:52 . dr-xr-x---. 4 root root 175 3æœˆ 10 21:45 .. -rw------- 1 root root 393 3æœˆ 10 21:52 authorized_keys -rw------- 1 root root 1675 3æœˆ 10 21:48 id_rsa -rw-r--r-- 1 root root 393 3æœˆ 10 21:48 id_rsa.pub -rw-r--r-- 1 root root 366 3æœˆ 10 21:54 known_hosts master é…ç½®å…å¯†ç™»å½•åˆ°master slave1 slave2 ssh-copy-id masterssh-copy-id slave1ssh-copy-id slave2 å››ã€å®‰è£…é…ç½® jdkç¼–è¯‘ç¯å¢ƒè½¯ä»¶å®‰è£…ç›®å½• mkdir -p /export/server JDK 1.8å®‰è£… ä¸Šä¼  jdk-8u241-linux-x64.tar.gzåˆ°/export/server/ç›®å½•ä¸‹ å¹¶è§£å‹æ–‡ä»¶ tar -zxvf jdk-8u241-linux-x64.tar.gz é…ç½®ç¯å¢ƒå˜é‡ vim /etc/profile export JAVA_HOME=/export/server/jdk1.8.0_241 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ source /etc/profile æŸ¥çœ‹ java ç‰ˆæœ¬å· java -version ç»“æœæ˜¾ç¤ºï¼š [root@master jdk1.8.0_241]# java -version java version â€œ1.8.0_241â€ Java(TM) SE Runtime Environment (build 1.8.0_241-b07) Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode) master èŠ‚ç‚¹å°† java ä¼ è¾“åˆ° slave1 å’Œ slave2 scp -r /export/server/jdk1.8.0_241/ root@slave1:/export/server/ scp -r /export/server/jdk1.8.0_241/ root@slave2:/export/server/ é…ç½® slave1 å’Œ slave2 çš„ jdk ç¯å¢ƒå˜é‡ï¼ˆæ³¨ï¼šå’Œä¸Šæ–¹ master çš„é…ç½®æ–¹æ³•ä¸€æ ·ï¼‰åœ¨ master slave1 å’Œslave2 åˆ›å»ºè½¯è¿æ¥ cd /export/serverln -s jdk1.8.0_241/ jdk é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ source /etc/profile zookeeperå®‰è£…é…ç½®é…ç½®ä¸»æœºåå’ŒIPçš„æ˜ å°„å…³ç³»ï¼Œä¿®æ”¹ /etc/hosts æ–‡ä»¶ï¼Œæ·»åŠ  master.root slave1.root slave2.root vim /etc/hosts #ç»“æœæ˜¾ç¤º 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.88.135 master master.root 192.168.88.136 slave1 slave1.root 192.168.88.137 slave2 slave2.root zookeeperå®‰è£… ä¸Šä¼  zookeeper-3.4.10.tar.gzåˆ°/export/server/ç›®å½•ä¸‹ å¹¶è§£å‹æ–‡ä»¶ cd /export/server/ tar -zxvf zookeeper-3.4.10.tar.gz åœ¨ /export/server ç›®å½•ä¸‹åˆ›å»ºè½¯è¿æ¥ cd /export/server ln -s zookeeper-3.4.10/ zookeeper è¿›å…¥ /export/server/zookeeper/conf/ å°† zoo_sample.cfg æ–‡ä»¶å¤åˆ¶ä¸ºæ–°æ–‡ä»¶ zoo.cfg cd /export/server/zookeeper/conf/ cp zoo_sample.cfg zoo.cfg æ¥ä¸Šæ­¥ç»™ zoo.cfg æ·»åŠ å†…å®¹ #Zookeeperçš„æ•°æ®å­˜æ”¾ç›®å½• dataDir=/export/server/zookeeper/zkdatas# ä¿ç•™å¤šå°‘ä¸ªå¿«ç…§ autopurge.snapRetainCount=3# æ—¥å¿—å¤šå°‘å°æ—¶æ¸…ç†ä¸€æ¬¡ autopurge.purgeInterval=1# é›†ç¾¤ä¸­æœåŠ¡å™¨åœ°å€ server.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888 è¿›å…¥ /export/server/zookeeper/zkdatas ç›®å½•åœ¨æ­¤ç›®å½•ä¸‹åˆ›å»º myid æ–‡ä»¶ï¼Œå°† 1 å†™å…¥è¿›å» cd /export/server/zookeeper/zkdata touch myid echo â€˜1â€™ &gt; myid å°† master èŠ‚ç‚¹ä¸­ /export/server/zookeeper-3.4.10 è·¯å¾„ä¸‹å†…å®¹æ¨é€ç»™slave1 å’Œ slave2 scp -r /export/server/zookeeper-3.4.10/ slave1:$PWD scp -r /export/server/zookeeper-3.4.10/ slave2:$PWD æ¨é€æˆåŠŸåï¼Œåˆ†åˆ«åœ¨ slave1 å’Œ slave2 ä¸Šåˆ›å»ºè½¯è¿æ¥ ln -s zookeeper-3.4.10/ zookeeper æ¥ä¸Šæ­¥æ¨é€å®Œæˆåå°† slave1 å’Œ slave2 çš„ /export/server/zookeeper/zkdatas/ æ–‡ä»¶å¤¹ä¸‹çš„ myidä¸­çš„å†…å®¹åˆ†åˆ«æ”¹ä¸º 2 å’Œ3 cd /export/server/zookeeper/zkdatas/ ç»“æœæ˜¾ç¤ºï¼š [root@slave1 zkdatas]# vim myid [root@slave1 zkdatas]# more myid 2[root@slave2 zkdatas]# vim myid [root@slave2 zkdatas]# more myid 3 é…ç½®zookeeperçš„ç¯å¢ƒå˜é‡ï¼ˆæ³¨ï¼šä¸‰å°ä¸»æœºéƒ½éœ€è¦é…ç½®ï¼‰ vim /etc/profile # zookeeper ç¯å¢ƒå˜é‡ export ZOOKEEPER_HOME=/export/server/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ source /etc/profile è¿›å…¥ /export/server/zookeeper-3.4.10/bin ç›®å½•ä¸‹å¯åŠ¨ zkServer.sh è„šæœ¬ ï¼ˆæ³¨ï¼šä¸‰å°éƒ½éœ€è¦åšï¼‰ cd /export/server/zookeeper-3.4.10/bin zkServer.sh startç»“æœæ˜¾ç¤ºï¼š [root@master bin]# ./zkServer.sh start ZooKeeper JMX enabled by default Using config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg Starting zookeeper â€¦ STARTED zookeeper çš„çŠ¶æ€ zkServer.sh status ç»“æœæ˜¾ç¤ºï¼š [root@master server]# zkServer.sh status ZooKeeper JMX enabled by default Using config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg Mode: follower [root@slave1 server]# zkServer.sh status ZooKeeper JMX enabled by default Using config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg Mode: follower [root@slave2 conf]# zkServer.sh status ZooKeeper JMX enabled by default Using config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg Mode: leader jps ç»“æœæ˜¾ç¤ºï¼š [root@master server]# jps 125348 QuorumPeerMain 16311 Jps [root@slave1 server]# jps 126688 QuorumPeerMain 17685 Jps [root@slave2 conf]# jps 126733 QuorumPeerMain 17727 Jps è„šæœ¬ä¸€é”®å¯åŠ¨ vim zkServer.sh#!/bin/bashif [ $# -eq 0 ] ;thenecho â€œplease input param:start stopâ€elseif [ $1 = start ] ;thenecho â€œ${1}ing masterâ€ssh master â€œsource /etc/profile;/export/server/zookeeper/bin/zkServer.sh startâ€for i in {1..2}doecho â€œ${1}ping slave${i}â€ ssh slave${i} \"source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start\" done fiif [ $1 = stop ];thenecho â€œ${1}ping master â€œssh master â€œsource /etc/profile;/export/server/zookeeper/bin/zkServer.sh stopâ€for i in {1..2}doecho â€œ${1}ping slave${i}â€ ssh slave${i} â€œsource /etc/profile;/export/server/zookeeper/bin/zkServer.sh stopâ€donefiif [ $1 = status ];thenecho â€œ${1}ing masterâ€ssh master â€œsource /etc/profile;/export/server/zookeeper/bin/zkServer.sh statusâ€for i in {1..2}doecho â€œ${1}ping slave${i}â€ssh slave${i} â€œsource /etc/profile;/export/server/zookeeper/bin/zkServer.sh statusâ€donefifi#å°†æ–‡ä»¶æ”¾åœ¨ /bin ç›®å½•ä¸‹ chmod +x zkServer-all.sh &amp;&amp; zkServer-all.sh Hadoop å®‰è£…é…ç½®æŠŠ hadoop-3.3.0-Centos7-64-with-snappy.tar.gz ä¸Šä¼ åˆ° /export/server å¹¶è§£å‹æ–‡ä»¶ tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz ä¿®æ”¹é…ç½®æ–‡ä»¶(è¿›å…¥è·¯å¾„ /export/server/hadoop-3.3.0/etc/hadoop) cd /export/server/hadoop-3.3.0/etc/hadoop hadoop-env.sh #æ–‡ä»¶æœ€åæ·»åŠ  export JAVA_HOME=/export/server/jdk1.8.0_241 export HDFS_NAMENODE_USER=root export HDFS_DATANODE_USER=root export HDFS_SECONDARYNAMENODE_USER=root export YARN_RESOURCEMANAGER_USER=root export YARN_NODEMANAGER_USER=root core-site.xml &lt;!-- è®¾ç½®é»˜è®¤ä½¿ç”¨çš„æ–‡ä»¶ç³»ç»Ÿ Hadoopæ”¯æŒfileã€HDFSã€GFSã€ali|Amazonäº‘ç­‰æ–‡ä»¶ç³»ç»Ÿ - -&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt; &lt;/property&gt; &lt;!-- è®¾ç½®Hadoopæœ¬åœ°ä¿å­˜æ•°æ®è·¯å¾„ --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt; &lt;/property&gt; &lt;!-- è®¾ç½®HDFS web UIç”¨æˆ·èº«ä»½ --&gt; &lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; hadoop.proxyuser.root.hosts * hadoop.proxyuser.root.groups * &lt; !â€“ æ–‡ä»¶ç³»ç»Ÿåƒåœ¾æ¡¶ä¿å­˜æ—¶é—´ â€“&gt; fs.trash.interval 1440 hdfs-site.xml dfs.namenode.secondary.http-address slave1:9868 mapred-site.xml mapreduce.framework.name yarn mapreduce.jobhistory.address master:10020 mapreduce.jobhistory.webapp.address master:19888 yarn.app.mapreduce.am.env HADOOP_MAPRED_HOME=${HADOOP_HOME} mapreduce.map.env HADOOP_MAPRED_HOME=${HADOOP_HOME} mapreduce.reduce.env HADOOP_MAPRED_HOME=${HADOOP_HOME} yarn-site.xml yarn.resourcemanager.hostname master yarn.nodemanager.aux-services mapreduce_shuffle yarn.nodemanager.pmem-check-enabled false yarn.nodemanager.vmem-check-enabled false yarn.log-aggregation-enable true yarn.log.server.url http://master:19888/jobhistory/logs yarn.log-aggregation.retain-seconds 604800 node1 node2 node3 åˆ†å‘åŒæ­¥hadoopå®‰è£…åŒ… cd /export/serverscp -r hadoop-3.3.0 root@slave1:$PWDscp -r hadoop-3.3.0 root@slave2:$PWDå°†hadoopæ·»åŠ åˆ°ç¯å¢ƒå˜é‡ vim /etc/profile export HADOOP_HOME=/export/server/hadoop-3.3.0 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶ source /etc/profile Hadoopé›†ç¾¤å¯åŠ¨ æ ¼å¼åŒ–namenodeï¼ˆåªæœ‰é¦–æ¬¡å¯åŠ¨éœ€è¦æ ¼å¼åŒ–ï¼‰ hdfs namenode -format è„šæœ¬ä¸€é”®å¯åŠ¨ [root@master ~]# start-dfs.sh Starting namenodes on [master] ä¸Šä¸€æ¬¡ç™»å½•ï¼šäº” 3æœˆ 11 21:27:24 CST 2022pts/0 ä¸Š Starting datanodes ä¸Šä¸€æ¬¡ç™»å½•ï¼šäº” 3æœˆ 11 21:27:32 CST 2022pts/0 ä¸Š Starting secondary namenodes [slave1] ä¸Šä¸€æ¬¡ç™»å½•ï¼šäº” 3æœˆ 11 21:27:35 CST 2022pts/0 ä¸Š [root@master ~]# start-yarn.sh Starting resourcemanager ä¸Šä¸€æ¬¡ç™»å½•ï¼šäº” 3æœˆ 11 21:27:41 CST 2022pts/0 ä¸Š Starting nodemanagers ä¸Šä¸€æ¬¡ç™»å½•ï¼šäº” 3æœˆ 11 21:27:51 CST 2022pts/0 ä¸Š å¯åŠ¨å è¾“å…¥ jps æŸ¥çœ‹ [root@master ~]# jps 127729 NameNode 127937 DataNode 14105 Jps 128812 NodeManager 128591 ResourceManager [root@slave1 hadoop]# jps 121889 NodeManager 121559 SecondaryNameNode 7014 Jps 121369 DataNode [root@slave2 hadoop]# jps 6673 Jps 121543 NodeManager 121098 DataNode WEBé¡µé¢HDFSé›†ç¾¤ï¼š http://master:9870/ YARNé›†ç¾¤ï¼š http://master:9870/","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-05-24T14:29:13.025Z","updated":"2022-05-24T14:29:13.025Z","comments":true,"path":"2022/05/24/hello-world/","link":"","permalink":"http://j-corleone.github.io/2022/05/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}