<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Corleone</title><meta name="author" content="Corleone"><link rel="shortcut icon" href="/img/logo.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Corleone" type="application/atom+xml">
</head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Corleone</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/#Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/"> About</a></li><li class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://phower.me"> Blog</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/luoxioahei.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Corleone</h3><p class="author-bio">hello</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-facebook-square" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-stack-overflow" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weibo" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-weixin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fab fa-qq" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li><li><a class="social-icon" href="/" target="_blank"><i class="fas fa-rss" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="/" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="/" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div><a class="cv-links" href="/attaches/CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>My Detail CV.</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">《Spark local& stand-alone配置》</h2><article><p>Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在<br>着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节<br>点，当 master 节点出现故障时，集群就不可用了。 spark-Standalone-HA 模式下<br>master 节点不固定，当一个宕机时，立即换另一台为 master 保障不出现故障。<br>此处因为先前配置时的 zookeeper 版本和 spark 版本不太兼容，导致此模式有故障，需要重新下<br>载配置新的版本的 zookeeper<br>配置之前需要删除三台主机的 旧版 zookeeper 以及 对应的软连接<br>在 master 节点上重新进行前面配置的 zookeeper 操作</p>
<blockquote>
<p>1.上传apache-zookeeper-3.7.0-bin.tar.gz 到/export/server/目录下 并解压文件 2.在 /export/server 目录下创建软连接 3.进入 /export/server/zookeeper/conf/ 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg 4.接上步给 zoo.cfg 添加内容 5.进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件，将 1 写入进 去6.将 master 节点中 /export/server/zookeeper-3.7.0 路径下内容推送给slave1 和 slave2 7.推送成功后，分别在 slave1 和 slave2 上创建软连接 8.接上步推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/文件夹 下的 myid 中的内容分别改为 2 和 3 配置环境变量： 因先前配置 zookeeper 时候创建过软连接且以 ’zookeeper‘ 为路径，所以不用配置环境变量，此 处也是创建软连接的方便之处</p>
</blockquote>
<p>进入 /export/server/spark/conf 文件夹 修改 spark-env.sh 文件内容</p>
<blockquote>
<p>cd /export/server/spark/conf<br>vim spark-env.sh</p>
</blockquote>
<p>为 83 行内容加上注释，此部分原为指定 某台主机 做 master ，加上注释后即为 任何主机都<br>可以做 master</p>
<blockquote>
<p>结果显示：<br>……<br>82 # 告知Spark的master运行在哪个机器上 83 # export SPARK_MASTER_HOST=master<br>………</p>
</blockquote>
<p>文末添加内容</p>
<blockquote>
<p>SPARK_DAEMON_JAVA_OPTS=”-Dspark.deploy.recoveryMode=ZOOKEEPER -<br>Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 - Dspark.deploy.zookeeper.dir=/spark-ha”<br>#spark.deploy.recoveryMode<br>指定HA模式 基于Zookeeper实现<br>#指定Zookeeper的连接地址<br>#指定在Zookeeper中注册临时节点的路径</p>
</blockquote>
<p>分发 spark-env.sh 到 salve1 和 slave2 上</p>
<blockquote>
<blockquote>
<pre class="line-numbers language-none"><code class="language-none">scp spark-env.sh slave1:/export/server/spark/conf/ 
scp spark-env.sh slave2:/export/server/spark/conf/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</blockquote>
</blockquote>
<p>启动之前确保 Zookeeper 和 HDFS 均已经启动<br>启动集群:</p>
<blockquote>
<p>#在 master 上 启动一个master 和全部worker /export/server/spark/sbin/start-all.sh # 注意, 下面命令在 slave1 上执行 启动 slave1 上的 master 做备用 master /export/server/spark/sbin/start-master.sh<br>结果显示：<br>(base) [root@master ~]# jps<br>37328 DataNode<br>41589 Master<br>35798 QuorumPeerMain<br>38521 ResourceManager<br>46281 Jps<br>38907 NodeManager<br>41821 Worker<br>36958 NameNode (base)<br>[root@slave1 sbin]# jps<br>36631 DataNode<br>48135 Master<br>35385 QuorumPeerMain<br>37961 NodeManager<br>40970 Worker<br>48282 Jps<br>37276 SecondaryNameNode</p>
</blockquote>
<p>访问 WebUI 界面</p>
<blockquote>
<blockquote>
<pre class="line-numbers language-none"><code class="language-none">http://master:8081/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
</blockquote>
<p>此时 kill 掉 master 上的 master 假设 master 主机宕机掉</p>
<blockquote>
<p>#master主机 master 的进程号 kill -9 41589 结果显示： (base) [root@master ~]# jps 37328 DataNode 90336 Jps 35798 QuorumPeerMain 38521 ResourceManager 38907 NodeManager 41821 Worker 36958 NameNode</p>
</blockquote>
<p>访问 slave1 的 WebUI</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
<p>进行主备切换的测试<br>提交一个 spark 任务到当前 活跃的 master上 :</p>
<blockquote>
<p>/export/server/spark/bin/spark-submit –master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000</p>
</blockquote>
<p>复制标签 kill 掉 master 的 进程号<br>再次访问 master 的 WebUI</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://master:8081/">http://master:8081/</a><br>网页访问不了！</p>
</blockquote>
<p>再次访问 slave1 的 WebUI</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://slave1:8082/">http://slave1:8082/</a></p>
</blockquote>
<p>可以看到当前活跃的 master 提示信息</p>
<blockquote>
<p>(base) [root@master ~]# /export/server/spark/bin/spark-submit –master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000 22/03/29 16:11:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnect… 22/03/29 16:12:16 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection… 22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnect… Pi is roughly 3.140960 (base) [root@master ~]#</p>
</blockquote>
<p>Spark On YARN模式</p>
<blockquote>
<p>在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无</p>
</blockquote>
<p>需部署Spark集群, 只要找一台服务器, 充当Spark的客户端<br>保证 HADOOP_CONF_和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中 （注: 前面配置spark-Standlone 时已经配置过此项了）</p>
<blockquote>
<p>spark-env.sh 文件部分显示： …. 77 ## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop 79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop ….</p>
</blockquote>
<p>链接到 YARN 中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）<br>bin/pyspark –master yarn –deploy-mode client|cluster # –deploy-mode 选项是指定部署模式, 默认是 客户端模式 # client就是客户端模式 # cluster就是集群模式 # –deploy-mode 仅可以用在YARN模式下<br>bin/spark-shell –master yarn –deploy-mode client|cluster<br>bin/spark-submit –master yarn –deploy-mode client|cluster /xxx/xxx/xxx.py 参数</p>
<blockquote>
<p>spark-submit 和 spark-shell 和 pyspark的相关参数</p>
</blockquote>
<ul>
<li><p>bin/pyspark: pyspark解释器spark环境 - bin/spark-shell: scala解释器spark环境 - bin/spark-submit: 提交jar包或Python文件执行的工具 - bin/spark-sql: sparksql客户端工具</p>
<p>这4个客户端工具的参数基本通用.以spark-submit 为例: bin/spark-submit –master spark://master:7077 xxx.py`</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]<br>Usage: spark-submit –kill [submission ID] –master [spark://…]<br>Usage: spark-submit –status [submission ID] –master [spark://…]<br>Usage: spark-submit run-example [options] example-class [example args]</p>
<blockquote>
</blockquote>
<p>Options: –master MASTER_URL spark://host:port, mesos://host:port, yarn, k8s://<a href="https://host:port/">https://host:port</a>, or</p>
<blockquote>
</blockquote>
<p>local (Default: local[*]). –deploy-mode DEPLOY_MODE 部署模式 client 或者 cluster 默认是client –class CLASS_NAME 运行java或者scala class(for Java / Scala apps). –name NAME 程序的名字 –jars JARS Comma-separated list of jars to include on the</p>
<blockquote>
</blockquote>
<p>driver and executor classpaths. –packages Comma-separated list of maven coordinates of</p>
<blockquote>
</blockquote>
<p>jars to include on the driver and executor classpaths. Will</p>
<blockquote>
</blockquote>
<p>search the local maven repo, then maven central and any</p>
<blockquote>
</blockquote>
<p>additional remote repositories given by –repositories. The</p>
<blockquote>
</blockquote>
<p>format for the coordinates should be</p>
<blockquote>
</blockquote>
<p>groupId:artifactId:version.<br>–exclude-packages Comma-separated list of groupId:artifactId, to exclude while resolving the dependencies provided in<br>– packages to avoid dependency conflicts. –repositories Comma-separated list of additional remote repositories to search for the maven coordinates given with<br>– packages.<br>–py-files PY_FILES 指定Python程序依赖的其它python文件<br>–files FILES Comma-separated list of files to be placed in the working directory of each executor. File paths of these files in executors can be accessed via SparkFiles.get(fileName).<br>–archives ARCHIVES Comma-separated list of archives to be extracted into the working directory of each executor.<br>–conf,<br>-c PROP=VALUE 手动指定配置<br>–properties-file FILE Path to a file from which to load extra properties. If not specified, this will look for conf/spark- defaults.conf. –driver-memory MEM Driver的可用内存(Default: 1024M). –driver-java-options Driver的一些Java选项 –driver-library-path Extra library path entries to pass to the driver. –driver-class-path Extra class path entries to pass to the driver. Note that jars added with –jars are automatically included in the classpath.<br>–executor-memory MEM Executor的内存 (Default: 1G).<br>–proxy-user NAME User to impersonate when submitting the application. This argument does not work with<br>–principal /<br>–keytab.<br>–help,<br>-h 显示帮助文件<br>–verbose,<br>-v Print additional debug output. –version, 打印版本 Cluster deploy mode only(集群模式专属):<br>–driver-cores NUM Driver可用的的CPU核数(Default: 1). Spark standalone or Mesos with cluster deploy mode only:<br>–supervise 如果给定, 可以尝试重启Driver Spark standalone, Mesos or K8s with cluster deploy mode only:<br>–kill SUBMISSION_ID 指定程序ID kill –status SUBMISSION_ID 指定程序ID 查看运行状态 Spark standalone, Mesos and Kubernetes only:<br>–total-executor-cores NUM 整个任务可以给Executor多少个CPU核心用 Spark standalone, YARN and Kubernetes only:<br>–executor-cores NUM 单个Executor能使用多少CPU核心 Spark on YARN and Kubernetes only(YARN模式下):<br>–num-executors NUM Executor应该开启几个<br>–principal PRINCIPAL Principal to be used to login to KDC.<br>–keytab KEYTAB The full path to the file that contains the keytab for the principal specified above. Spark on YARN only:<br>–queue QUEUE_NAME 指定运行的YARN队列(Default: “default”)</p>
</blockquote>
</blockquote>
</li>
</ul>
<p>启动 YARN 的历史服务器</p>
<blockquote>
<p>cd /export/server/hadoop-3.3.0/sbin ./mr-jobhistory-daemon.sh start historyserver</p>
</blockquote>
<p>访问WebUI界面</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://master:19888/">http://master:19888/</a></p>
</blockquote>
<p>client 模式测试</p>
<blockquote>
<p>SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit –master yarn –deploy-mode client – driver-memory 512m –executor-memory 512m –num-executors 1 –total- executor-cores 2 ${SPARK_HOME}/examples/src/main/python/pi.py</p>
</blockquote>
<p>cluster 模式测试</p>
<blockquote>
<p>SPARK_HOME=/export/server/spark ${SPARK_HOME}/bin/spark-submit –master yarn –deploy-mode cluster –driver- memory 512m –executor-memory 512m –num-executors 1 –total-executor-cores 2 –conf “spark.pyspark.driver.python=/root/anaconda3/bin/python3” –conf “spark.pyspark.python=/root/anaconda3/bin/python3” ${SPARK_HOME}/examples/src/main/python/pi.py 3**</p>
</blockquote>
<p>《Spark local&amp; stand-alone配置》</p>
<p>**</p>
<p>本地模式(单机) 本地模式就是以一个独立的进程,通过其内部的多个线程来模拟整个Spark运行时环境<br>Anaconda On Linux 安装 (单台服务器脚本安装)<br>安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装<br>位置在 /export/server:</p>
<blockquote>
<p>cd /export/server<br>#运行文件 sh Anaconda3-2021.05-Linux-x86_64.sh<br>过程显示：<br>…<br>#出现内容选 yes Please answer ‘yes’ or ‘no’:’ &gt;&gt;&gt; yes …<br>#出现添加路径：/export/server/anaconda3<br>…<br>[/root/anaconda3]</p>
<p>/export/server/anaconda3 PREFIX=/export/server/anaconda3<br>…</p>
</blockquote>
<p>安装完成后, 退出终端， 重新进来:</p>
<blockquote>
<p>exit<br>结果显示：<br>#看到这个Base开头表明安装好了.base是默认的虚拟环境. Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1 (base)<br>[root@node1 ~]#</p>
</blockquote>
<p>创建虚拟环境 pyspark 基于 python3.8</p>
<blockquote>
<p>conda create -n pyspark python=3.8</p>
</blockquote>
<p>切换到虚拟环境内</p>
<blockquote>
<p>conda activate pyspark 结果显示： (base) [root@node1 ~]# conda activate pyspark (pyspark) [root@node1 ~]#</p>
</blockquote>
<p>在虚拟环境内安装包 （有WARNING不用管）</p>
<blockquote>
<p>pip install pyhive pyspark jieba -i <a target="_blank" rel="noopener" href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p>
</blockquote>
<p>spark 安装<br>将文件上传到 /export/server 里面 ，解压</p>
<blockquote>
<p>cd /export/server # 解压 tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/</p>
</blockquote>
<p>建立软连接</p>
<blockquote>
<p>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</p>
</blockquote>
<p>添加环境变量</p>
<blockquote>
<p>SPARK_HOME: 表示Spark安装路径在哪里<br>PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器<br>JAVA_HOME: 告知Spark Java在哪里<br>HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里<br>HADOOP_HOME: 告知Spark Hadoop安装在哪里</p>
</blockquote>
<p>vim /etc/profile<br>内容：<br>…..<br>注：此部分之前配置过，此部分不需要在配置<br>#JAVA_HOME export JAVA_HOME=/export/server/jdk1.8.0_241 export PATH=$PATH:$JAVA_HOME/bin export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</p>
<p>#HADOOP_HOME export HADOOP_HOME=/export/server/hadoop-3.3.0 export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</p>
<p>#ZOOKEEPER_HOME export ZOOKEEPER_HOME=/export/server/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/bin …..</p>
<p>#将以下部分添加进去 #SPARK_HOME export SPARK_HOME=/export/server/spark #HADOOP_CONF_DIR export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop #PYSPARK_PYTHON export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python<br>vim .bashrc<br>内容添加进去：</p>
<p>#JAVA_HOME<br>export JAVA_HOME=/export/server/jdk1.8.0_241<br>#PYSPARK_PYTHON<br>export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python</p>
<p>重新加载环境变量文件</p>
<blockquote>
<p>source /etc/profile<br>source ~/.bashrc</p>
</blockquote>
<p>进入 /export/server/anaconda3/envs/pyspark/bin/ 文件夹</p>
<blockquote>
<p>cd /export/server/anaconda3/envs/pyspark/bin/</p>
</blockquote>
<p>开启</p>
<blockquote>
<p>./pyspark 结果显示： (base) [root@master bin]# ./pyspark<br>Python 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0] :: Anaconda, Inc. on linux<br>Type “help”, “copyright”, “credits” or “license” for more information.<br>Setting default log level to “WARN”. To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). 2022-03-15 20:37:04,612 WARN util.NativeCodeLoader: Unable to load native- hadoop library for your platform… using builtin-java classes where applicable<br>Welcome to</p>
<hr>
<p>__ / <strong>/</strong> ___ <em>****/ /**<br>*\ / _ / _ `/ <em>*/ ‘*/<br>/</em>* / .**/</em>,*/<em>/ /</em>/_\ version 3.2.0<br>/<em>/<br>Using Python version 3.8.12 (default, Oct 12 2021 13:49:34) Spark context Web UI available at <a target="_blank" rel="noopener" href="http://master:4040/">http://master:4040</a> Spark context available as ‘sc’ (master = local[</em>], app id = local- 1647347826262). SparkSession available as ‘spark’. &gt;&gt;&gt;</p>
</blockquote>
<p>查看WebUI界面</p>
<blockquote>
<p>浏览器访问：<br><a target="_blank" rel="noopener" href="http://node1:4040/">http://node1:4040/</a></p>
</blockquote>
<p>退出</p>
<blockquote>
<p>conda deactivate</p>
</blockquote>
<p>Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境 Anaconda On Linux 安装 (单台服务器脚本安装 注：在 slave1 和 slave2 上部署)<br>安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 /export/server:</p>
<p>cd /export/server # 运行文件 sh Anaconda3-2021.05-Linux-x86_64.sh</p>
<blockquote>
<p>过程显示：<br>…<br>#出现内容选 yes<br>Please answer ‘yes’ or ‘no’:’<br>yes<br>…<br>#出现添加路径：/export/server/anaconda3<br>…<br>[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3 PREFIX=/export/server/anaconda3<br>…</p>
</blockquote>
<p>安装完成后, 退出终端，</p>
<blockquote>
<p>重新进来:<br>exit<br>结果显示：<br>#看到这个Base开头表明安装好了.base是默认的虚拟环境.<br>Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1<br>…</p>
</blockquote>
<p>在 master 节点上把 ./bashrc 和 profile 分发给 slave1 和 slave2</p>
<blockquote>
<p>#分发 .bashrc : scp <del>/.bashrc root@slave1:</del>/ scp <del>/.bashrc root@slave2:</del>/ #分发 profile : scp /etc/profile/ root@slave1:/etc/ scp /etc/profile/ root@slave2:/etc/<br>…</p>
</blockquote>
<p>创建虚拟环境 pyspark 基于 python3.8</p>
<blockquote>
<p>conda create -n pyspark python=3.8</p>
</blockquote>
<p>切换到虚拟环境内</p>
<blockquote>
<p>conda activate pyspark 结果显示： (base) [root@node1 ~]# conda activate pyspark (pyspark)<br>在虚拟环境内安装包 （有WARNING不用管）<br>pip install pyhive pyspark jieba -i <a target="_blank" rel="noopener" href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>spark 安装<br>将文件上传到 /export/server 里面 ，解压</p>
</blockquote>
<p>master 节点节点进入 /export/server/spark/conf 修改以下配置文件</p>
<blockquote>
<p>cd /export/server/spark/conf</p>
</blockquote>
<p>将文件 workers.template 改名为 workers，并配置文件内容</p>
<blockquote>
<p>mv workers.template workers vim workers<br># localhost删除，内容追加文末： node1<br>node2<br>node3<br># 功能: 这个文件就是指示了 当前SparkStandAlone环境下, 有哪些worker</p>
</blockquote>
<p>将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容</p>
<blockquote>
<p>mv spark-env.sh.template spark-env.sh vim spark-env.sh</p>
</blockquote>
<blockquote>
<p>文末追加内容：<br>##设置JAVA安装目录 JAVA_HOME=/export/server/jdk<br>##HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop YARN_CONF_DIR=/export/server/hadoop/etc/hadoop ## 指定spark老大Master的IP和提交任务的通信端口 # 告知Spark的master运行在哪个机器上 export SPARK_MASTER_HOST=master<br>#告知sparkmaster的通讯端口 export SPARK_MASTER_PORT=7077<br># 告知spark master的 webui端口 SPARK_MASTER_WEBUI_PORT=8080<br># worker cpu可用核数 SPARK_WORKER_CORES=1<br># worker可用内存 SPARK_WORKER_MEMORY=1g<br># worker的工作通讯地址 SPARK_WORKER_PORT=7078<br># worker的 webui地址 SPARK_WORKER_WEBUI_PORT=8081<br>## 设置历史服务器 # 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中 SPARK_HISTORY_OPTS=”- Dspark.history.fs.logDirectory=hdfs://master:8020/sparklog/ - Dspark.history.fs.cleaner.enabled=true”</p>
</blockquote>
<p>开启 hadoop 的 hdfs 和 yarn 集群</p>
<blockquote>
<blockquote>
<pre class="line-numbers language-none"><code class="language-none">start-dfs.sh 
start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下:</p>
<p>hadoop fs -mkdir /sparklog hadoop fs -chmod 777 /sparklog</p>
</blockquote>
</blockquote>
<p>将 spark-defaults.conf.template 改为 spark-defaults.conf 并做相关配置</p>
<blockquote>
<p>mv spark-defaults.conf.template spark-defaults.conf vim spark-defaults.conf 文末追加内容为： # 开启spark的日期记录功能 spark.eventLog.enabled true # 设置spark日志记录的路径 spark.eventLog.dir hdfs://master:8020/sparklog/ # 设置spark日志是否启动压缩 spark.eventLog.compress true</p>
</blockquote>
<p>配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory=INFO, console 改为<br>log4j.rootCategory=WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为<br>WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息）</p>
<blockquote>
<p>mv log4j.properties.template log4j.properties vim log4j.properties 结果显示：<br>…<br>18 # Set everything to be logged to the console<br>19 log4j.rootCategory=WARN, console ….</p>
</blockquote>
<p>master 节点分发 spark 安装文件夹 到 slave1 和 slave2 上</p>
<blockquote>
<p>master 节点分发 spark 安装文件夹 到 slave1 和 slave2 上</p>
</blockquote>
<p>在slave1 和 slave2 上做软连接</p>
<blockquote>
<p>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</p>
</blockquote>
<p>重新加载环境变量</p>
<blockquote>
<p>source /etc/profile</p>
</blockquote>
<p>进入 /export/server/spark/sbin 文件目录下 启动 start-history-server.sh</p>
<blockquote>
<p>cd /export/server/spark/sbin ./start-history-server.sh</p>
</blockquote>
<p>访问 WebUI 界面</p>
<blockquote>
<p>浏览器访问： <a target="_blank" rel="noopener" href="http://master:18080/">http://master:18080/</a></p>
</blockquote>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/#Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/"> About</a></li><li class="nav_item"><a class="nav-page" target="_blank" rel="noopener" href="https://phower.me"> Blog</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2022 by Corleone</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>